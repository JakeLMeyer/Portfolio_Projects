# Variational Autoencoder
Documentation Date: 05/29/2023 <br>
Author: Jake Meyer

## Project Description
The purpose for this project was to implement a variational autoencoder with the MNIST data set. The high-level steps were creating the appropriate directories, creating a ConvNet, generating a sampling function, decoder implementation, creating a custom variational layer class, instantiating, and training the model, and then generating/saving a plot.  A grid (15 x 15) of digits was saved as an output. 

## Table of Contents
<ol>
    <li>Supporting Files
    <li>Project Environment Overview
    <li>High-Level Steps
    <li>Report an Issue
    <li>Project References
    <li>Project Citation
    <li>Github-Page Return
</ol>

## Supporting Files
MNIST Dataset.

## Project Environment Overview
The project was completed in Jupyter Notebook (through Anaconda Navigator) via Python. All relevant libraries are called out in the Import Necessary Libraries section of the code.

## High-Level Steps
Create directories, create encoder network (Simple Convnet),  create sampling function, decoder implementation, create custom variational layer class, instantiate and train the model, generate plot and save as output to results directory.

## Report an Issue
In the event of an error or major concerns, please reach out to my email via meyerjake@gmail.com.

## Project References
Using code examples from Chapter 6 of First Edition: [deep-learning-with-python-notebooks](https://github.com/fchollet/deep-learning-with-python-notebooks)

## Citation for this Project
Meyer, J. (2023, August 11). *Variational Autoencoder*. JakeLMeyer Portfolio Projects. https://github.com/JakeLMeyer/Portfolio_Projects/tree/main/Variational_Autoencoder_MNIST_Data

## Return to Jake Meyer Github-Page
Github-Page - [Jake Meyer Github-Page](https://jakelmeyer.github.io)<br>